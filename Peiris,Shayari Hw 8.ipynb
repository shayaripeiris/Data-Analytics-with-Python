{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8\n",
    "\n",
    "## Name: Shayari Peiris\n",
    "\n",
    "### Partner: Veer Kumar\n",
    " \n",
    "### Collaborators:Vishvesh Srinivisan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework covers KNN, Decision Trees, and Random Forests. The first question will be a review for training KNN model. The second sequence of questions will give an in depth look at the gini impurity and how training a decision tree actually works. Then the questions will cover basic implimentations of both DT's and RF's along with an intro to tuning hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It might be useful to load the ones you know you will use first, and then as you figure out what other ones you need\n",
    "#come back here and load those ones in as well'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "(a) Load the diabetes dataset and name it 'df'. Conduct data cleaning.\n",
    "\n",
    "- Perform any data cleaning or data transformation steps if required\n",
    "- State some of the data cleaning steps which you can perform on **any** data set\n",
    "\n",
    "(b) Create two dataframes for features and target variables (Outcome). Conduct a full model training and testing (30%) for a KNN model with K=5. Print the accuracy, confusion matrix, and explain what the confuison matrix tells you\n",
    "\n",
    "(c) Create a range from 1 to 50 going at steps of 2 then make a list where you will store average accuracy at each k value\n",
    "use a for loop to compute the average accuracy over 10-fold cross validation for each k value. Plot the average accuracy for each k values and determine which k value you will choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1 (a)\n",
    "# Load the diabetes dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Describing the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the above stats we can see that there are people with 0 BP, 0 skin thickness, and 0 Glucose, which aren't feasible so we must treat them as NaN values.\n",
    "df[\"Glucose\"] = df[\"Glucose\"].apply(lambda x: np.nan if x == 0 else x)\n",
    "df[\"BloodPressure\"] = df[\"BloodPressure\"].apply(lambda x: np.nan if x == 0 else x)\n",
    "df[\"SkinThickness\"] = df[\"SkinThickness\"].apply(lambda x: np.nan if x == 0 else x)\n",
    "df[\"Insulin\"] = df[\"Insulin\"].apply(lambda x: np.nan if x == 0 else x)\n",
    "df[\"BMI\"] = df[\"BMI\"].apply(lambda x: np.nan if x == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   0\n",
       "Glucose                       5\n",
       "BloodPressure                35\n",
       "SkinThickness               227\n",
       "Insulin                     374\n",
       "BMI                          11\n",
       "DiabetesPedigreeFunction      0\n",
       "Age                           0\n",
       "Outcome                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                  0.000000\n",
       "Glucose                      0.651042\n",
       "BloodPressure                4.557292\n",
       "SkinThickness               29.557292\n",
       "Insulin                     48.697917\n",
       "BMI                          1.432292\n",
       "DiabetesPedigreeFunction     0.000000\n",
       "Age                          0.000000\n",
       "Outcome                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see that the Insulin column has nearly 50% of NaN values. Therefore, it would be appropriate to drop the column completely\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Insulin\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0.901674\n",
       "Glucose                     0.530989\n",
       "BloodPressure               0.134153\n",
       "SkinThickness               0.690619\n",
       "BMI                         0.593970\n",
       "DiabetesPedigreeFunction    1.919911\n",
       "Age                         1.129597\n",
       "Outcome                     0.635017\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For highly skewed values we'll impute the column with median else mean.\n",
    "# Highly skewed\n",
    "df[\"BMI\"].replace(to_replace=np.nan,value=df[\"BMI\"].median(), inplace=True)\n",
    "df[\"Pregnancies\"].replace(to_replace=np.nan,value=df[\"Pregnancies\"].median(), inplace=True)\n",
    "\n",
    "# Normal\n",
    "df[\"Glucose\"].replace(to_replace=np.nan,value=df[\"Glucose\"].mean(), inplace=True)\n",
    "df[\"BloodPressure\"].replace(to_replace=np.nan,value=df[\"BloodPressure\"].mean(), inplace=True)\n",
    "df[\"SkinThickness\"].replace(to_replace=np.nan,value=df[\"SkinThickness\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To clean the data and check for null values, you can recode variables and drop variables with alot of missing data and replace null values with means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 (b)\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "y= df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a basic KNN model with K = 5\n",
    "\n",
    "# First learning model (k = 5)\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fitting the model\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is equal to 74.46%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of our model\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "print('Accuracy of our model is equal to ' + str(round(accuracy, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  24]\n",
      " [ 35  46]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix for variables with 2 labels\n",
    "\n",
    "Conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(Conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 (c)\n",
    "# creating a list of K for KNN\n",
    "#The model will consider K values from 1 till 50 with an interval of 2 (All odd numbers from 1 till 30)\n",
    "k_list = list(range(1,50,2))\n",
    "\n",
    "# Creating list of Average Accuracy for each Cross-validation\n",
    "cv_scores = []\n",
    "\n",
    "# Performing 10-fold cross validation\n",
    "for k in k_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting average Accuracy for all number of neighbors\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('The optimal number of neighbors', fontsize=20, fontweight='bold')\n",
    "plt.xlabel('Number of Neighbors K', fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.plot(k_list, cv_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on the plot I would choose K=36, because it's got highest accuracy for model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "The goal of Q2 is to make a function that can calculate the weighted gini impurity over any grouping and any size of classes. (Note: There will be lab notes explaining the gini impurity and how to calculate it)\n",
    "\n",
    "(a) Calculate the gini impurity of the example by hand. Then write some code to do it for you. You will have to find $p_0$ and $p_1$ which are the probabilities of selecting a 0 and a 1 (respectively) from the group.\n",
    "\n",
    "(b) Now say we have two groups? Calculate the gini index of each group (with some code). Now, make a weighted sum of the gini numbers, each weighted by the proportion of the group size to the total number of entries (i.e. if group 1 is of length 10 and group 2 is of length 15, then group 1 would have a weight of 2/5 and group 2 a weight of 3/5).\n",
    "\n",
    "(c) Generalize that bit of code you wrote to now deal with any number of groups with any number of classes. Assume the groups will be given as a list of lists, and if there is an empty group the gini number will be 0 (there needs to be an if statement to make sure we do not divide by 0).\n",
    "\n",
    "(d) Make that bit of code into a function called gini_imp which takes a 'groups' variable and a 'classes' variable. It should return the gini index. Note, you need to use the classes variable because that is how you know what classes to check for in each group. Test it on the same example from part (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini impurity: 0.4444444444444445\n"
     ]
    }
   ],
   "source": [
    "#Q2 (a)\n",
    "\n",
    "###This is the example\n",
    "classes = [0,1]\n",
    "group = [0,0,0,1,1,0,1,0,0]\n",
    "\n",
    "p0=group.count(0)/len(group)\n",
    "p1=group.count(1)/len(group)\n",
    "gini_impurity=1-p0**2-p1**2\n",
    "print('gini impurity:',gini_impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini index for group 0: 0.375\n",
      "gini index for group :1 0.6875\n",
      "weighted gini index: 0.5684210526315789\n"
     ]
    }
   ],
   "source": [
    "#Q2 (b)\n",
    "classes = [0,1]\n",
    "groups = [[0,0,0,1],[0,0,1,1]]\n",
    "g0_p0=groups[0].count(0)/len(groups[0])\n",
    "g0_p1=groups[0].count(1)/len(groups[0])\n",
    "g0_gini=1-g0_p0**2-g0_p1**2\n",
    "print('gini index for group 0:',g0_gini)\n",
    "g1_p0=groups[1].count(0)/len(groups[1])\n",
    "g1_p1=groups[0].count(1)/len(groups[1])\n",
    "g1_gini=1-g1_p0**2-g1_p1**2\n",
    "print('gini index for group :1',g1_gini)\n",
    "weigthed_gini=0.5*g0_gini+0.5*g1_gini\n",
    "print('weighted gini index:',weighted_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ginis: [0.5599999999999999, 0.375, 0.625, 0, 0.6666666666666667]\n",
      "weighted gini: 0.5684210526315789\n"
     ]
    }
   ],
   "source": [
    "#Q2 (c)\n",
    "###test your bit of code with:\n",
    "classes = [0,1,2,3]\n",
    "groups = [[0,3,1,1,1],[0,0,0,1],[2,3,1,1],[],[0,0,1,1,2,2]]\n",
    "\n",
    "ginis=[]\n",
    "for group in groups:\n",
    "    if len(group)==0:\n",
    "        ginis.append(0)\n",
    "    else:\n",
    "        gini=0\n",
    "        for c in classes:\n",
    "            gini+=(group.count(c)/len(group))**2\n",
    "        gini=1-gini\n",
    "        ginis.append(gini)\n",
    "print('ginis:',ginis)\n",
    "weighted_gini=0\n",
    "total_length=sum([len(group) for group in groups])\n",
    "for i in range(len(groups)):\n",
    "    weighted_gini+=len(groups[i])/total_length*ginis[i]\n",
    "print('weighted gini:',weighted_gini)\n",
    "###You should get a gini number equal to 0.5684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5684210526315789"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2 (d)\n",
    "classes = [0,1,2,3]\n",
    "groups = [[0,3,1,1,1],[0,0,0,1],[2,3,1,1],[],[0,0,1,1,2,2]]\n",
    "def gini_imp(groups,classes):\n",
    "    ginis=[]\n",
    "    for group in groups:\n",
    "        if len(group)==0:\n",
    "            ginis.append(0)\n",
    "        else:\n",
    "            gini=0\n",
    "            for c in classes:\n",
    "                gini+=(group.count(c)/len(group))**2\n",
    "            gini=1-gini\n",
    "            ginis.append(gini)\n",
    "    weighted_gini=0\n",
    "    total_length=sum([len(group) for group in groups])\n",
    "    for i in range(len(groups)):\n",
    "        weighted_gini+=len(groups[i])/total_length*ginis[i]\n",
    "    return weighted_gini\n",
    "\n",
    "gini_imp(groups,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "To make a full decision trees\n",
    "\n",
    "(a) Load the datasets titanic_train_data and titanic_test_data into dataframes and split them into X_train, X_test, y_train and y_test (the training sets are coming from the titanic train data and visa versa). Note, the first two columns should be deleted because they are just passenger Id's, also documentation about the data can be found here:https://www.kaggle.com/azeembootwala/titanic. Create a Decision Tree instance, fit the data on the training sets and get the accuracy score on the test set. Report the confusion matrix.\n",
    "\n",
    "(b) Split the X_train and y_train data into sets called X_train,X_val, y_train, y_val using train_test_split. We are going to try and tune some parameters in the Decision tree. Called a new Decision Tree instance with the following parameters: **max_features, max_depth, and min_samples_leaf**. Choose some value to test them with, and run the model a few times to see if you can get different accuracy scores (use the X_val and y_val to get the accuracy scores). What do these parameters do? (Look them up in the documentation)\n",
    "\n",
    "(c) We are going to use the validation sets to try and find the best parameter combinations. So, use a triple for loop to iterate over different ranges for each of the three parameters, find what combination gives the best accuracy on the validation set. Then, use that combination on a decision tree to classify the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 (a)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix)\n",
    "#Loading dataset\n",
    "\n",
    "titanic_train_data= pd.read_csv('titanic_train_data.csv')\n",
    "titanic_test_data=pd.read_csv('titanic_test_data.csv')\n",
    "titanic_train_data.drop(columns=titanic_train_data.columns[[0,1]], axis=1, inplace=True)\n",
    "titanic_test_data.drop(columns=titanic_test_data.columns[[0,1]], axis=1, inplace=True)\n",
    "X_train=titanic_train_data.drop(['Survived'],axis=1)\n",
    "X_test=titanic_test_data.drop(['Survived'],axis=1)\n",
    "y_test=titanic_test_data[['Survived']]\n",
    "y_train=titanic_train_data[['Survived']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Decision Tree model using DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to print evaluation metrics\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True, pos_label=\"Yes\"):\n",
    "    if train == False:\n",
    "        pred = clf.predict(X_test)\n",
    "        print(\"Test Result:\\n\")        \n",
    "        print(f\"accuracy score: {accuracy_score(y_test, pred)}\\n\")\n",
    "        print(f\"Classification Report: \\n \\tPrecision: {precision_score(y_test, pred)}\\n\\tRecall Score: {recall_score(y_test, pred)}\\n\\tF1 score: {f1_score(y_test, pred)}\\n\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "\n",
      "accuracy score: 0.8\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.7\n",
      "\tRecall Score: 0.7777777777777778\n",
      "\tF1 score: 0.7368421052631577\n",
      "\n",
      "Confusion Matrix: \n",
      " [[52 12]\n",
      " [ 8 28]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating decision tree model\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1, max_features=2, min_samples_leaf=2,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3b\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "tree_clf=DecisionTreeClassifier(max_depth = 1,min_samples_leaf = 2, max_features = 2,random_state=42)\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_depth:The maximum depth for growing each tree: an integer between 1 and 100, inclusive.\n",
    "#minimum_samples_leaf:The minimum number of samples each branch must have after splitting a node\n",
    "#max_features:The number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "\n",
      "accuracy score: 0.6233766233766234\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.4673913043478261\n",
      "\tRecall Score: 0.5308641975308642\n",
      "\tF1 score: 0.4971098265895954\n",
      "\n",
      "Confusion Matrix: \n",
      " [[101  49]\n",
      " [ 38  43]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating decision tree model\n",
    "print_score(tree_clf, X_train, y_train, X_val, y_val, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6859 candidates, totalling 20577 fits\n",
      "Best paramters: {'max_depth': 4, 'max_features': 3, 'min_samples_leaf': 15})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veer2\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "12996 fits failed out of a total of 20577.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12996 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\veer2\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\veer2\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\veer2\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\veer2\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.67225326 0.67225326 0.67225326 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, max_features=3, min_samples_leaf=15)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3 (c)\n",
    "params = {\"max_depth\":(list(range(1, 20))), \n",
    "    \"max_features\":(list(range(1, 20))), \n",
    "    \"min_samples_leaf\":list(range(1, 20)), \n",
    "}\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(**best_params)\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "\n",
      "accuracy score: 0.7272727272727273\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.625\n",
      "\tRecall Score: 0.5555555555555556\n",
      "\tF1 score: 0.5882352941176471\n",
      "\n",
      "Confusion Matrix: \n",
      " [[123  27]\n",
      " [ 36  45]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_clf=DecisionTreeClassifier(max_depth=4, max_features=3, min_samples_leaf=15,random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "#Evaluating decision tree model\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Let's move onto random forests, we'll be doing more parameter tuning here.\n",
    "\n",
    "(a) With the original train and test sets, run a Random Forest model on the data and report the accuracy score. How does it compare to the scores in Question 3?\n",
    "\n",
    "(b) Create the train and validation sets again, and create a Random Forest Classifier with the following parameters: **n_estimators, max_leaf_nodes, max_depth**, with some values. What do this parameters do? (Again look up the documentation) Run the model and see how the accuracy changes. Change the values and try to get a higher accuracy.\n",
    "\n",
    "(c) Similar to Question 3 part (c), use a triple for loop to iterate over combinations of parameter values for the random forest and find one that is optimal in accuracy. How does this accuracy compare to the others we have seen?\n",
    "\n",
    "Note: This kind of parameter opimization can be done using built in python functions, GridSearchCV and RandomSearchCV both are methods that take in some kind of range / distribution for the parameters and finds the best one (and uses cross validation which is a bonus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4 (a)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Fitting the random forest model using RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Q3a we got accuracy=0.8 and in Q4a we get a slightly better accuracy of 0.83."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating random forest model using the previously created function\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Q4 (b)\n",
    "rf_clf = RandomForestClassifier(n_estimators=3, max_leaf_nodes=2, max_depth=3)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the accuracy in Q3b is 0.62 and it in Q4b it is 0.63, so accuracy improves slightly.\n",
    "#n_estimators : This is the number of trees you want to build before taking the maximum voting or averages of predictions.\n",
    "#max_depth:The number of splits that each decision tree is allowed to make. If the number of splits is too low, the model underfits the data and if it is too high the model overfits. Generally, we go with a max depth of 3, 5, or 7\n",
    "#max_leaf_nodes:Maximum number of leaf nodes a decision tree can have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4 (c)\n",
    "params = {\"n_estimators\":(list(range(1, 10))), \n",
    "    \"max_features\":(list(range(1, 10))), \n",
    "    \"min_samples_leaf\":list(range(1, 20)), \n",
    "}\n",
    "\n",
    "\n",
    "tree_clf = RandomForestClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")\n",
    "\n",
    "tree_clf = RandomForestClassifier(**best_params)\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As compared to Q3c where we have obtained an accuracy of 0.72, the accuracy for Q4c is 0.87 which has slightly improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "\n",
    "Come up with an analogy for decision tree's v. random forest's and why random forests avoid the problem of overfitting. (+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
